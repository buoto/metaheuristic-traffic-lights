---
title: "Sygnalizacja świetlna"
author: "Michał Błotniak & Adrianna Małkiewicz"
date: "10.06.2017"
output:
  pdf_document: default
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE)
library(knitr)
source('algorithm.R')
source('simulation.R')
```

# Realizacja
Celem projektu było rozwiązanie problemu optymalizacji działania sygnalizacji świetlnej na skrzyżowaniu. Poszukiwany
był taki podział czasu świateł, który spowodowałby minimalizację sumarycznego czasu spędzonego przez wszystkie samochody
na skrzyżowaniu. Szczegółowe informacje zostały zawarte w pliku _koncepcja.pdf_. Poniżej znajdują się również
doprecyzowane kwestie.

W zadaniu nie była brana pod uwagę przepustowość (liczba samochodów, którym udało się w ciągu całej doby przejechać).
Za wartość minimalizowaną została przyjęta suma czasów oczekiwania samochodów na wjazd na skrzyżowanie, ponieważ tak
było zdefiniowane przydzielone zadanie. Co więcej, wartości te są od siebie zależne, więc w obu przypadkach
zaimplementowany algorytm zachowywałby się tak samo.

Pojęcie jednej instancji problemu zostało przedefiniowane na pojedynczy przebieg symulacji dla podanych parametrów
rozkładów prawdopodobienstw przyjazdu samochodu oraz czasu przejazdu przez skrzyżowanie. Z tego wynika, że funkcja celu
jest niedeterministyczna.

## Symulacja (_simulation.R_)
Zadaniem tego modułu było zasymulowanie ruchu samochodów na skrzyżowaniu dla podanych czasów zmiany świateł oraz
rozkładów prawdopodobieństwa przyjazdów samochodów z każdej strony skrzyżowania o określonej porze dnia. Czas przejazdu
jednego samochodu przez skrzyżowanie został zamodelowany poprzez połówkowy rozkład normalny, zamiast normalnego - daje
to pewność, że czas przejazdu przez skrzyżownanie nie będzie ujemny.

Na początku każdego kroku algorytmu, na podstawie rozkładu prawdopodobieństwa dla danej pory dnia, symulowany jest
przyjazd samochodów na skrzyżowanie. Następnie, przejeżdżają kolejno samochody z kierunków N/S, przez czas określony
parametrem dla tego kroku. Jeśli wszystkie samochody z tych kierunków przejadą, to prostopadłe kierunki czekają na
zmianę światła, a następnie przejeżdżają przez skrzyżowanie do końca czasu bieżącego kroku. Jeśli światło zmieni się
zanim wszystkie samochody zjadą ze skrzyżowania, to czekają na kolejną zmianę świateł.

Dodatkowo w trakcie każdego cyklu świateł sumowany jest czas przebywania samochodów na skrzyżowaniu - od chwili
przyjazdu, do czasu ruszenia ze skrzyżowania. W ten sposób określana jest jakość przekazanego jako argument punktu
przestrzeni problemu.

## Metoda optymalizacji (_algorithm.R_)
Zaimplementowany algorytm został zmodyfikowany względem tego opisanego w koncepcji. Główną różnicą jest dobór osobników
do krzyżowania. W obecnej wersji z populacji wybierane są pary zgodnie z opisanymi wcześniej regułami selekcji
proporcjonalnej. Dodatkowo wykorzystywana jest sukcesja generacyjna - potomstwo w pełni zastępuje pokolenie rodziców.
Zmiany były podyktowane kwestiami wydajnościowymi. Wykorzystywane wcześniej krzyżowanie każdy z każdym wymagało
wielokrotnego uruchamiania symulacji dla potomstwa niskiej jakości.

W trakcie działania algorytmu zapisywany jest najlepszy osobnik ze wszystkich pokoleń. Osobnik ten jest zwracany
po osiągnięciu limitu pokoleń `maxSteps`. 

Zaimplementowany algorytm minimalizuje funkcję celu.

### Opis argumentów
- `heuristic` - funkcja przyjmująca `n` wymiarowy punkt przestrzeni rozwiązania i zwracająca jego ocenę,
- `min` - kres dolny przestrzeni rozwiązań,
- `max` - kres górny przestrzeni rozwiązań,
- `mu` - wielkość populacji,
- `maxSteps` - liczba generowanych pokoleń,
- `mutationMean` - wartość średnia rozkładu mutacji.

Podczas eksperymentów dostrajane były parametry `mu`, `maxSteps`, `mutationMean`, `mutationSd`.

Argumenty `mu` i `maxSteps` wpływają na działanie algorytmu w podobny sposób - wraz z ich zwiększeniem algorytm znajduje
lepsze rozwiązania kosztem wydłużenia czasu obliczeń. Badany jednak będzie stosunek `mu` do `maxSteps`, w celu ustalenia,
czy lepiej jest wygenerować większą populację na początku i mniejszą ilość pokoleń, czy na odwrót. Strojenie tych
parametrów będzie zatem przeprowadzane z ustalonym stosunkiem wartości `maxSteps = 1000/mu`.

Odpowiednio duże wartości parametrów `mutationMean`, `mutationSd` pozwalają algorytmowi na opuszczenie minimum lokalnego
wspomagając eksplorację. Jednakże zbyt duże zwiększenie tych argumentów pogorsza jakość znajdowanych optimów. Strojenie
będzie polegało na sprawdzeniu, jakie wartości poprawiają działanie algorytmu przy założeniu $mutationMean = mutationSd$.

# Przebieg eksperymentów
Do przeprowadzenia eksperymentu został przyjęty podział doby na 720 kawałków (po 2 minuty), w trakcie których
każdorazowo wykonywany jest pełen cykl zmiany świateł. Zostały również przyjęte przykładowe wartości parametrów
symulacji, bazując na średniej przepustowości polskich dróg z [Generalnego Pomiaru Ruchu GDDKiA](https://www.gddkia.gov.pl/userfiles/articles/g/generalny-pomiar-ruchu-w-2015_15598//SYNTEZA/Synteza_GPR2015.pdf)
(średni ruch = $11178 poj./24~godz. \approx 15 poj./2~min.$). Modelowana jest sytuacja, gdy trasa N/S ma większą
przepustowość niż trasa W/E.

```{r init traffic}
trafficDists <- list(morning = c(20, 17, 6, 9),
                     noon = c(11, 9, 15, 5),
                     afternoon = c(18, 19, 8, 7),
                     night = c(4, 3, 1, 2))
```

Powyższa lista zawiera wektory wartości oczekiwanych rozkładów natężenia ruchu (liczba samochodów przyjeżdżających
w kwancie czasu) z każdego kierunku i dla kolejnych pór dnia.

Przyjęty został także średni czas zjeżdżania ze skrzyżowania równy $8s$. Wartość oczekiwana połówkowego rozkładu
normalnego wynosi $1/\theta$, zatem współczynnik $\theta$ jest równy $\theta = \frac{2~min.}{8~s} = 15$

```{r init heur}
theta <- 15
h <- function(point) simulate(point, trafficDists = trafficDists, list(theta = theta)) 
```

Z uwagi na niedeterminizm działania algorytmu, będzie on powtarzany `iter` razy.

```{r iter}
iter <- 10
```

Jedynie na potrzeby strojenia algorytmu, liczba pokoleń `n` zostaje zmniejszona do 72:

```{r n}
n <- 72
```

Przestrzeń przeszukiwań jest ograniczona wektorami:

```{r min max, echo=TRUE}
minPoint <- rep(0, n)
maxPoint <- rep(1, n)
```

Dodatkowo przyjęte zostały punkty referencyjne ze stałą proporcją podziału cyklu świateł ustaloną a priori
($1/2$, $2/3$ i $3/4$ czasu dla kierunku N/S):

```{r init rep}
ref.1.2 <- rep(1/2, n)
ref.2.3 <- rep(2/3, n)
ref.3.4 <- rep(3/4, n)

ref.1.2.results <- replicate(iter, h(ref.1.2))
ref.2.3.results <- replicate(iter, h(ref.2.3))
ref.3.4.results <- replicate(iter, h(ref.3.4))
```

Poniżej prezentowane jest zestawienie wyników otrzymywanych w symulacjach dla punktów referencyjnych.

```{r rep boxplot, echo=FALSE}
boxplot(list('h(ref.1.2)' = ref.1.2.results,
             'h(ref.2.3)' = ref.2.3.results,
             'h(ref.3.4)' = ref.3.4.results))
```

Jak widać, lepsze wyniki uzyskują strategie faworyzujące kierunek N/S. Trudno jest jednoznacznie określić, który sposób
jest najlepszy, z racji zbliżonych wartości średnich i odchyleń standardowych.

## Analiza działania algorytmu

### Strojenie wartości `mu` i `maxSteps`
Dla ustalonych:

```{r init mutation}
mutationMean <- 0.1
mutationSd <- 0.1
```

Poniższy eksperyment ma na celu rozstrzygnięcie jaki stosunek `mu` do `maxSteps` daje najlepszy wynik działania
algorytmu.

```{r run algorithm, message=FALSE, warning=FALSE}
mus <- c(2, 10, 100)

results <- list()

for (mu in mus) {
  message(mu)
  maxSteps <- 1000/mu
  hs <- c()
  
  for (i in 1:iter) {
    sol <- mea(h,
               min = minPoint,
               max = maxPoint,
               mu = mu,
               maxSteps = maxSteps,
               mutationMean = mutationMean,
               mutationSd = mutationSd)
    hs <- c(hs, sol$h)
  }
  
  results <- c(results, list(hs))
}

df <- data.frame(mu = mus, maxSteps = 1000/mus, mean = sapply(results, mean), sd = sapply(results, sd))
```
```{r run algo table, echo=FALSE}
kable(df, caption = paste('Wyniki pomiarów dla ', iter, ' powtórzeń z różnymi wartościami $\\mu$ i $maxSteps$.'))

boxplot(list("mu = 2" = results[[1]],
             "mu = 10" = results[[2]],
             "mu = 100" = results[[3]]))
```

### Wnioski
Eksperyment wykazał, że mała liczba osobników daje słaby rezultat. W przypadku pozostałych dwóch wartości wartość
średnia i odchylenie standardowe są prawie identyczne, gdyż w obu przypadkach algorytm był w stanie przejrzeć taką samą
liczbę punktów. Jednakże wariant z większym rozmiarem populacji rzadziej osiadał w minimum lokalnym, z powodu dłużej
utrzymującego się rozproszenia populacji.

### Strojenie wartości `mutationMean` i `mutationSd`
Dla ustalonych:

```{r init vars}
mu <- 10
maxSteps <- 100
```

Zostaną zbadane następujące parametry $mutationMean = mutationSd = 0.1$, $mutationMean = mutationSd = 0.05$ oraz $mutationMean = mutationSd = 0.01$

```{r run algorithm mutation, message=FALSE, warning=FALSE}
params <- c(0.1, 0.05, 0.01)
results.m <- list()

for (param in params) {
  message(param)
  mutationMean = param
  mutationSd = param
  hs.m <- c()
  
  for (i in 1:iter) {
    sol.m <- mea(h,
                 min = minPoint,
                 max = maxPoint,
                 mu = mu,
                 maxSteps = maxSteps,
                 mutationMean = mutationMean,
                 mutationSd = mutationSd)
    hs.m <- c(hs.m, sol.m$h)
  }
  
  results.m <- c(results.m, list(hs.m))
}

df.m <- data.frame(mutationMean = params, mean = sapply(results.m, mean), sd = sapply(results.m, sd))
```

```{r run algo mutation table, echo=FALSE}
kable(df.m, caption = paste('Wyniki pomiarów dla ', iter, ' powtórzeń z różnymi wartościami $mutationMean$ i $mutationSd$.'))

boxplot(list("param = 0.1" = results.m[[1]],
             "param = 0.05" = results.m[[2]],
             "param = 0.01" = results.m[[3]]))
```

### Wnioski
Na powyższym wykresie można zaobserwować, że jakość rozwiązań generowanych przez algorytm rośnie wraz ze spadkiem
wartości oczekiwanej i wariancji mutacji. Eksperyment pokazuje, że algorytm uruchomiony z parametrem $0.01$ daje najlepsze
wyniki. Dodatkowo widać, iż zmniejszenie siły mutacji skutkowało większą wariancją otrzymywanych wyników, co może wynikać
z przedwczesnego wpadania w minima lokalne. Mimo to wciąż uzystkiwano wartości co najmniej tak dobre jak dla wartości $0.05$,
dlatego wartość $0.01$ zostanie wykorzystana w docelowym wywołaniu. 

## Wyniki dla realistycznego przypadku
Przyjmując ponownie $n = 720$, poszukiwane będzie rozwiązanie przypadku założonego na początku analizy. Pokaże to, że
algorytm znajduje lepsze rozwiązania, niż ustalony z góry, stały podział, podsumowując wyniki naszej pracy.

```{r run algorithm real, message=FALSE, warning=FALSE}
ref.1.2.r <- rep(1/2, 720)
ref.2.3.r <- rep(2/3, 720)
ref.3.4.r <- rep(3/4, 720)

ref.1.2.r.results <- replicate(iter, h(ref.1.2.r))
ref.2.3.r.results <- replicate(iter, h(ref.2.3.r))
ref.3.4.r.results <- replicate(iter, h(ref.3.4.r))

sol.r <- mea(h,
             min = rep(0, 720),
             max = rep(1, 720),
             mu = 10,
             maxSteps = 100,
             mutationMean = 0.01,
             mutationSd = 0.01)

sol.r.results <- replicate(iter, h(sol.r$point))

```

```{r real boxplot, echo=FALSE}
data.r <- list(sol.r.results, ref.1.2.r.results, ref.2.3.r.results, ref.3.4.r.results)
df.r <- data.frame(mean = sapply(data.r, mean), sd = sapply(data.r, sd))
rownames(df.r) <- c("sol.r", "ref.1.2", "ref.2.3", "ref.3.4")
kable(df.r)

boxplot(list('h(sol.r)' = sol.r.results,
             'h(ref.1.2)' = ref.1.2.r.results,
             'h(ref.2.3)' = ref.2.3.r.results,
             'h(ref.3.4)' = ref.3.4.r.results))
```

### Wnioski
Jak widać na powyższych diagramach punkt otrzymany już w setnej generacji osiągnął ponad dwukrotnie lepszy wynik od
metod referencyjnych. Widoczna na diagramie wariancja wynika z niedeterminizmu funkcji oceny i jest podobna co
do rzędu wielkości we wszystkich przypadkach.

# Podsumowanie
Zaimplementowany algorytm spełnił założone zadanie - osiągnął wynik znacznie lepszy od z góry ustalonych strategii.
Pomimo niedeterminizmu funkcji celu wykorzystana metoda poradziła sobie dobrze w jej minimalizowaniu.
Dodatkowo interfejs algorytmu oferuje kilka parametrów modyfikujących jego zachowanie pozwalających na dostosowanie
jego zachowania do innych problemów. 

Sporym kłopotem okazała się złożoność obliczeniowa symulacji. W przypadku algorytmu ewolucyjnego, gdzie jej wartość
obliczana jest wielokrotnie, znacznie utrudniło to strojenie algorytmu, zwłaszcza dla dużych wartości natężenia ruchu.
